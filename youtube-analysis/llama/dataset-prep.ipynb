{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Creating training instructions...\n",
      "Creating validation instructions...\n",
      "Saving datasets...\n",
      "Created 130 training samples\n",
      "Created 50 validation samples\n",
      "\n",
      "Example instruction:\n",
      "{\n",
      "  \"instruction\": \"Recommend videos for someone who enjoyed watching this:\",\n",
      "  \"input\": \"{\\n  \\\"current_video\\\": {\\n    \\\"title\\\": \\\"Why is the Indian Economy bleeding talent? Socio-economic case study\\\",\\n    \\\"category\\\": \\\"Education\\\",\\n    \\\"duration\\\": 1227,\\n    \\\"duration_category\\\": 5,\\n    \\\"days_since_publication\\\": 0\\n  },\\n  \\\"viewing_history\\\": []\\n}\",\n",
      "  \"output\": \"{\\n  \\\"recommendations\\\": [\\n    {\\n      \\\"title\\\": \\\"Is Modi Confident of a 2024 Win? | What's the Maths of INDIA Alliance? | Akash Banerjee & Adwaith\\\",\\n      \\\"category\\\": \\\"Education\\\",\\n      \\\"reason\\\": \\\"Similar Education content with 5 duration\\\"\\n    }\\n  ]\\n}\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from typing import List, Dict\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def convert_to_serializable(obj):\n",
    "    \"\"\"Convert numpy/pandas numeric types to Python native types.\"\"\"\n",
    "    if isinstance(obj, (np.integer, np.int64)):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, (np.floating, np.float64)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    return obj\n",
    "\n",
    "def get_similar_videos(df: pd.DataFrame, current_video: pd.Series, num_samples: int = 3) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Helper function to get similar videos with proper error handling\n",
    "    \"\"\"\n",
    "    # Try exact category and duration match\n",
    "    similar_videos_df = df[\n",
    "        (df['Category'] == current_video['Category']) & \n",
    "        (df['Duration Category'] == current_video['Duration Category']) &\n",
    "        (df['Title'] != current_video['Title'])\n",
    "    ]\n",
    "    \n",
    "    # If no matches, try category only\n",
    "    if len(similar_videos_df) == 0:\n",
    "        similar_videos_df = df[\n",
    "            (df['Category'] == current_video['Category']) &\n",
    "            (df['Title'] != current_video['Title'])\n",
    "        ]\n",
    "    \n",
    "    # If still no matches, get random videos from different category\n",
    "    if len(similar_videos_df) == 0:\n",
    "        similar_videos_df = df[df['Title'] != current_video['Title']]\n",
    "    \n",
    "    # Determine number of samples to take\n",
    "    n_samples = min(num_samples, len(similar_videos_df))\n",
    "    \n",
    "    if n_samples > 0:\n",
    "        # Convert to records and ensure all numeric values are serializable\n",
    "        records = similar_videos_df.sample(n=n_samples).to_dict('records')\n",
    "        return [{k: convert_to_serializable(v) for k, v in record.items()} for record in records]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def create_instruction_dataset(df: pd.DataFrame) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Create instruction-following dataset with robust error handling\n",
    "    \"\"\"\n",
    "    instructions = []\n",
    "    \n",
    "    instruction_templates = [\n",
    "        \"Given this video viewing history, recommend similar videos:\",\n",
    "        \"Based on this watched video, suggest what to watch next:\",\n",
    "        \"Find videos similar to this one in terms of content and duration:\",\n",
    "        \"Recommend videos for someone who enjoyed watching this:\",\n",
    "        \"What other videos would interest someone who watched this video?\"\n",
    "    ]\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            # Get recent viewing history for context\n",
    "            history = df.iloc[max(0, idx-3):idx].to_dict('records')\n",
    "            history = [{k: convert_to_serializable(v) for k, v in record.items()} for record in history]\n",
    "            \n",
    "            # Create video context\n",
    "            video_context = {\n",
    "                'current_video': {\n",
    "                    'title': row['Title'],\n",
    "                    'category': row['Category'],\n",
    "                    'duration': convert_to_serializable(row['Duration']),\n",
    "                    'duration_category': row['Duration Category'],\n",
    "                    'days_since_publication': convert_to_serializable(row['Days Since Publication'])\n",
    "                },\n",
    "                'viewing_history': [{'title': v['Title'], 'category': v['Category']} for v in history]\n",
    "            }\n",
    "            \n",
    "            # Get similar videos\n",
    "            similar_videos = get_similar_videos(df, row)\n",
    "            \n",
    "            if not similar_videos:\n",
    "                continue\n",
    "            \n",
    "            # Format output\n",
    "            output = {\n",
    "                'recommendations': [\n",
    "                    {\n",
    "                        'title': video['Title'],\n",
    "                        'category': video['Category'],\n",
    "                        'reason': (f\"Similar {video['Category']} content with {video['Duration Category']} duration\" \n",
    "                                 if video['Duration Category'] == row['Duration Category']\n",
    "                                 else f\"Similar {video['Category']} content\")\n",
    "                    }\n",
    "                    for video in similar_videos\n",
    "                ]\n",
    "            }\n",
    "            \n",
    "            # Verify JSON serialization works\n",
    "            try:\n",
    "                json.dumps(video_context)\n",
    "                json.dumps(output)\n",
    "            except TypeError:\n",
    "                continue\n",
    "            \n",
    "            # Create instruction sample\n",
    "            instruction = {\n",
    "                'instruction': random.choice(instruction_templates),\n",
    "                'input': json.dumps(video_context, indent=2),\n",
    "                'output': json.dumps(output, indent=2)\n",
    "            }\n",
    "            \n",
    "            instructions.append(instruction)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {idx}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return instructions\n",
    "\n",
    "def create_validation_samples(df: pd.DataFrame, num_samples: int = 50) -> List[Dict]:\n",
    "    \"\"\"Create validation samples with robust error handling.\"\"\"\n",
    "    validation_samples = []\n",
    "    attempts = 0\n",
    "    max_attempts = num_samples * 2  # Allow some retry attempts\n",
    "    \n",
    "    while len(validation_samples) < num_samples and attempts < max_attempts:\n",
    "        try:\n",
    "            # Randomly select a video\n",
    "            row = df.sample(1).iloc[0]\n",
    "            \n",
    "            # Get similar videos\n",
    "            similar_videos = get_similar_videos(df, row, num_samples=2)\n",
    "            \n",
    "            if not similar_videos:\n",
    "                attempts += 1\n",
    "                continue\n",
    "            \n",
    "            # Create validation sample with serializable values\n",
    "            sample = {\n",
    "                'instruction': \"Recommend similar videos based on this viewing:\",\n",
    "                'input': json.dumps({\n",
    "                    'video': {\n",
    "                        'title': row['Title'],\n",
    "                        'category': row['Category'],\n",
    "                        'duration': convert_to_serializable(row['Duration']),\n",
    "                    }\n",
    "                }, indent=2),\n",
    "                'output': json.dumps({\n",
    "                    'recommendations': [\n",
    "                        {\n",
    "                            'title': video['Title'],\n",
    "                            'category': video['Category'],\n",
    "                        }\n",
    "                        for video in similar_videos\n",
    "                    ]\n",
    "                }, indent=2)\n",
    "            }\n",
    "            \n",
    "            # Verify JSON serialization works\n",
    "            try:\n",
    "                json.dumps(sample)\n",
    "                validation_samples.append(sample)\n",
    "            except TypeError as e:\n",
    "                print(f\"Error creating validation sample: {str(e)}\")\n",
    "                attempts += 1\n",
    "                continue\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error creating validation sample: {str(e)}\")\n",
    "            attempts += 1\n",
    "            continue\n",
    "    \n",
    "    return validation_samples\n",
    "\n",
    "def save_instruction_dataset(instructions: List[Dict], output_path: str):\n",
    "    \"\"\"Save the instruction dataset in JSONL format.\"\"\"\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for instruction in instructions:\n",
    "            f.write(json.dumps(instruction) + '\\n')\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # Load dataset\n",
    "        print(\"Loading dataset...\")\n",
    "        df = pd.read_csv('cleaned_data_final.csv')\n",
    "        \n",
    "        if len(df) == 0:\n",
    "            raise ValueError(\"Empty dataset\")\n",
    "        \n",
    "        # Create training instructions\n",
    "        print(\"Creating training instructions...\")\n",
    "        train_instructions = create_instruction_dataset(df)\n",
    "        \n",
    "        if not train_instructions:\n",
    "            raise ValueError(\"No training instructions could be created\")\n",
    "        \n",
    "        # Create validation instructions\n",
    "        print(\"Creating validation instructions...\")\n",
    "        valid_instructions = create_validation_samples(df)\n",
    "        \n",
    "        if not valid_instructions:\n",
    "            raise ValueError(\"No validation instructions could be created\")\n",
    "        \n",
    "        # Save datasets\n",
    "        print(\"Saving datasets...\")\n",
    "        save_instruction_dataset(train_instructions, 'train_instructions.jsonl')\n",
    "        save_instruction_dataset(valid_instructions, 'valid_instructions.jsonl')\n",
    "        \n",
    "        print(f\"Created {len(train_instructions)} training samples\")\n",
    "        print(f\"Created {len(valid_instructions)} validation samples\")\n",
    "        \n",
    "        # Print example\n",
    "        print(\"\\nExample instruction:\")\n",
    "        print(json.dumps(train_instructions[0], indent=2))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
