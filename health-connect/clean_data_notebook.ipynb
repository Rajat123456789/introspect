{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the CSV files\n",
    "data_dir = \"Data\"\n",
    "# username = \"someshbgd3\"\n",
    "username = \"gaurav_surtani\"\n",
    "\n",
    "# List of available health metrics\n",
    "METRICS_str = \"activeCaloriesBurned, basalBodyTemperature, basalMetabolicRate, bloodGlucose, bloodPressure, bodyFat, bodyTemperature, boneMass, cervicalMucus, distance, exerciseSession, elevationGained, floorsClimbed, heartRate, height, hydration, leanBodyMass, menstruationFlow, menstruationPeriod, nutrition, ovulationTest, oxygenSaturation, power, respiratoryRate, restingHeartRate, sleepSession, speed, steps, stepsCadence, totalCaloriesBurned, vo2Max, weight, wheelchairPushes\"\n",
    "METRICS = METRICS_str.split(\", \")\n",
    "\n",
    "# Initialize dictionary\n",
    "METRICS_dict = {}\n",
    "\n",
    "# Assign keys to dictionary with relevant columns\n",
    "# METRICS_dict[METRICS[0]] = []  # activeCaloriesBurned\n",
    "# METRICS_dict[METRICS[1]] = []  # basalBodyTemperature\n",
    "METRICS_dict[METRICS[2]] = [\"_id\", \"id\", \"end\"]  # basalMetabolicRate\n",
    "# METRICS_dict[METRICS[3]] = []  # bloodGlucose\n",
    "# METRICS_dict[METRICS[4]] = []  # bloodPressure\n",
    "METRICS_dict[METRICS[5]] = [\"_id\", \"id\", \"end\"]  # bodyFat\n",
    "# METRICS_dict[METRICS[6]] = []  # bodyTemperature\n",
    "# METRICS_dict[METRICS[7]] = []  # boneMass\n",
    "# METRICS_dict[METRICS[8]] = []  # cervicalMucus\n",
    "METRICS_dict[METRICS[9]] = [\"_id\", \"id\"]  # distance\n",
    "METRICS_dict[METRICS[10]] = [\"_id\", \"id\"]  # exerciseSession\n",
    "METRICS_dict[METRICS[11]] = [\"_id\", \"id\"]  # elevationGained\n",
    "METRICS_dict[METRICS[12]] = [\"_id\", \"id\"]  # floorsClimbed\n",
    "METRICS_dict[METRICS[13]] = [\"_id\", \"id\", \"end\", \"start\"]  # heartRate\n",
    "METRICS_dict[METRICS[14]] = [\"_id\", \"id\", \"end\"]  # height\n",
    "# METRICS_dict[METRICS[15]] = []  # hydration\n",
    "# METRICS_dict[METRICS[16]] = []  # leanBodyMass\n",
    "# METRICS_dict[METRICS[17]] = []  # menstruationFlow\n",
    "# METRICS_dict[METRICS[18]] = []  # menstruationPeriod\n",
    "METRICS_dict[METRICS[19]] = [\"_id\", \"id\", \"end\"]  # nutrition\n",
    "# METRICS_dict[METRICS[20]] = []  # ovulationTest\n",
    "METRICS_dict[METRICS[21]] = [\"_id\", \"id\", \"end\"]  # oxygenSaturation\n",
    "METRICS_dict[METRICS[22]] = []  # power\n",
    "METRICS_dict[METRICS[23]] = []  # respiratoryRate\n",
    "METRICS_dict[METRICS[24]] = []  # restingHeartRate\n",
    "METRICS_dict[METRICS[25]] = [\"_id\", \"id\"]  # sleepSession # STAGE_AWAKE  STAGE_LIGHT  STAGE_DEEP  STAGE_REM\n",
    "METRICS_dict[METRICS[26]] = [\"_id\", \"id\"]  # speed\n",
    "METRICS_dict[METRICS[27]] = [\"_id\", \"id\", \"end\"]  # steps\n",
    "# METRICS_dict[METRICS[28]] = []  # stepsCadence\n",
    "METRICS_dict[METRICS[29]] = [\"_id\", \"id\"]  # totalCaloriesBurned\n",
    "# METRICS_dict[METRICS[30]] = [\"_id\", \"id\", \"end\"]  # vo2Max\n",
    "METRICS_dict[METRICS[31]] = [\"_id\", \"id\", \"end\"]  # weight\n",
    "# METRICS_dict[METRICS[32]] = []  # wheelchairPushes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(username, metric):\n",
    "    # try:\n",
    "    file_path = os.path.join(data_dir, f\"./{username}/Uncleaned/{metric}_{username}.csv\")\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"❌ {metric} CSV file does not exist\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(df, metric):\n",
    "    df.drop(columns=METRICS_dict[metric], inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_data_column(df, metric):\n",
    "    expanded_rows = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            data_dict = ast.literal_eval(row[\"data\"].replace(\"'\", \"\\\"\"))  # Convert string to dict safely\n",
    "            flattened_data = {}\n",
    "\n",
    "            # Flatten nested dictionaries\n",
    "            for key, value in data_dict.items():\n",
    "                if isinstance(value, dict):  \n",
    "                    for sub_key, sub_value in value.items():\n",
    "                        flattened_data[f\"{metric}_{key}_{sub_key}\"] = sub_value\n",
    "                else:\n",
    "                    flattened_data[f\"{metric}_{key}\"] = value\n",
    "            \n",
    "            # Combine with existing row data\n",
    "            new_row = row.to_dict()\n",
    "            new_row.pop(\"data\")  # Remove original data column\n",
    "            new_row.update(flattened_data)  # Add expanded data attributes\n",
    "\n",
    "            expanded_rows.append(new_row)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing row: {row['data']} - {e}\")\n",
    "\n",
    "        df_expanded = pd.DataFrame(expanded_rows)\n",
    "        \n",
    "        if \"start\" in df_expanded.columns:\n",
    "            df_expanded[\"start\"] = pd.to_datetime(df_expanded[\"start\"], format=\"ISO8601\", errors=\"coerce\")\n",
    "            df_expanded[\"start\"] = df_expanded[\"start\"].dt.round(\"min\")\n",
    "        if \"end\" in df_expanded.columns:\n",
    "            df_expanded[\"end\"] = pd.to_datetime(df_expanded[\"end\"], format=\"ISO8601\", errors=\"coerce\")\n",
    "            df_expanded[\"end\"] = df_expanded[\"end\"].dt.round(\"min\")\n",
    "        \n",
    "         # Add total_time column (difference in minutes)\n",
    "        if \"start\" in df_expanded.columns and \"end\" in df_expanded.columns:\n",
    "            df_expanded[f\"{metric}_total_time\"] = (df_expanded[\"end\"] - df_expanded[\"start\"]).dt.total_seconds() / 60  # Convert to minutes\n",
    "\n",
    "\n",
    "    return df_expanded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_heart_beat(df, metric):\n",
    "    \"\"\"\n",
    "    Expands the 'data' column into separate columns for each attribute.\n",
    "    If the column contains a list (e.g., samples), each entry is expanded into a new row.\n",
    "    \"\"\"\n",
    "    expanded_rows = []\n",
    "    data_column = \"data\"\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            data_content = row[data_column]\n",
    "\n",
    "            # Convert string representation of dictionary to actual dictionary\n",
    "            data_parsed = ast.literal_eval(data_content.replace(\"'\", \"\\\"\")) if isinstance(data_content, str) else data_content\n",
    "            \n",
    "            if isinstance(data_parsed, dict) and \"samples\" in data_parsed:\n",
    "                for sample in data_parsed[\"samples\"]:\n",
    "                    new_row = row.to_dict()  # Copy original row\n",
    "                    new_row.pop(data_column)  # Remove the original JSON column\n",
    "                    new_row.update(sample)  # Add extracted values (beatsPerMinute & time)\n",
    "                    expanded_rows.append(new_row)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing row: {row[data_column]} - {e}\")\n",
    "            \n",
    "    df_expanded = pd.DataFrame(expanded_rows)\n",
    "    \n",
    "    if \"time\" in df_expanded.columns:\n",
    "        df_expanded[\"time\"] = pd.to_datetime(df_expanded[\"time\"], format='ISO8601')  # Convert time to datetime\n",
    "        df_expanded = df_expanded.sort_values(by=\"time\")  # Sort by time\n",
    "                \n",
    "    # Ensure 'time' column is in datetime format\n",
    "    if \"time\" in df_expanded.columns:\n",
    "        df_expanded[\"minute\"] = df_expanded[\"time\"].dt.round(\"min\")\n",
    "\n",
    "        # Group by minute and calculate rounded average\n",
    "        df_grouped = df_expanded.groupby([\"app\", \"minute\"], as_index=False).agg(\n",
    "            beatsPerMinute=(\"beatsPerMinute\", lambda x: round(np.mean(x)))  # Rounded average\n",
    "        )\n",
    "\n",
    "        # Rename 'minute' column back to 'time'\n",
    "        df_grouped.rename(columns={\"minute\": \"time\"}, inplace=True)\n",
    "\n",
    "    return df_grouped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_vitamin_grams(df, metric):\n",
    "    extracted_rows = []\n",
    "    data_column = \"data\"\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            data_content = row[data_column]\n",
    "\n",
    "            # Convert string representation of dictionary to actual dictionary\n",
    "            data_parsed = ast.literal_eval(data_content.replace(\"'\", \"\\\"\")) if isinstance(data_content, str) else data_content\n",
    "            \n",
    "            if isinstance(data_parsed, dict):\n",
    "                flattened_data = {}\n",
    "\n",
    "                for key, value in data_parsed.items():\n",
    "                    if isinstance(value, dict) and \"inGrams\" in value:\n",
    "                        flattened_data[f\"{key}_inGrams\"] = value[\"inGrams\"]  # Extract only 'inGrams'\n",
    "\n",
    "                new_row = row.to_dict()\n",
    "                new_row.pop(data_column)  # Remove the original JSON column\n",
    "                new_row.update(flattened_data)  # Add extracted nutrient data\n",
    "                extracted_rows.append(new_row)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing row: {row[data_column]} - {e}\")\n",
    "    \n",
    "    df_expanded = pd.DataFrame(extracted_rows)\n",
    "    \n",
    "    df_expanded[\"start\"] = pd.to_datetime(df_expanded[\"start\"], format=\"ISO8601\", errors=\"coerce\")\n",
    "    df_expanded[\"start\"] = df_expanded[\"start\"].dt.round(\"min\")\n",
    "\n",
    "    return df_expanded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sleep_data(df, metric, data_column=\"data\"):\n",
    "    stage_columns = [\"sleep_stage_1\", \"sleep_stage_2\", \"sleep_stage_3\", \"sleep_stage_4\"]\n",
    "    new_rows = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            # Parse the JSON-like string\n",
    "            sleep_data = ast.literal_eval(row[data_column].replace(\"'\", \"\\\"\")) if isinstance(row[data_column], str) else row[data_column]\n",
    "\n",
    "            # Initialize sleep stage times\n",
    "            sleep_stage_times = {f\"sleep_stage_{i}\": timedelta(0) for i in range(1, 9)}\n",
    "\n",
    "            if isinstance(sleep_data, dict) and \"stages\" in sleep_data:\n",
    "                for stage_info in sleep_data[\"stages\"]:\n",
    "                    start_time = datetime.fromisoformat(stage_info[\"startTime\"].replace(\"Z\", \"\"))\n",
    "                    end_time = datetime.fromisoformat(stage_info[\"endTime\"].replace(\"Z\", \"\"))\n",
    "                    duration = end_time - start_time  # Calculate duration\n",
    "\n",
    "                    # Accumulate duration based on stage\n",
    "                    stage_key = f\"sleep_stage_{stage_info['stage']}\"\n",
    "                    if stage_key in sleep_stage_times:\n",
    "                        sleep_stage_times[stage_key] += duration\n",
    "\n",
    "            # Compute total sleep time using row's `start` and `end` columns\n",
    "            total_sleep_time = None\n",
    "            if \"start\" in row and \"end\" in row:\n",
    "                try:\n",
    "                    start_time = datetime.fromisoformat(row[\"start\"].replace(\"Z\", \"\"))\n",
    "                    end_time = datetime.fromisoformat(row[\"end\"].replace(\"Z\", \"\"))\n",
    "                    total_sleep_time = end_time - start_time\n",
    "                except Exception:\n",
    "                    total_sleep_time = None  # Handle incorrect formats\n",
    "\n",
    "            # Convert timedelta to minutes for easy analysis\n",
    "            row_data = row.to_dict()\n",
    "            for stage in sleep_stage_times:\n",
    "                row_data[stage] = sleep_stage_times[stage].total_seconds() / 60  # Convert to minutes\n",
    "\n",
    "            row_data[\"total_sleep_time\"] = total_sleep_time.total_seconds() / 60 if total_sleep_time else None  # Convert to minutes\n",
    "            new_rows.append(row_data)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing row: {row[data_column]} - {e}\")\n",
    "\n",
    "        df_expanded = pd.DataFrame(new_rows)\n",
    "        \n",
    "        if \"start\" in df_expanded.columns:\n",
    "            df_expanded[\"start\"] = pd.to_datetime(df_expanded[\"start\"], format=\"ISO8601\", errors=\"coerce\")\n",
    "            df_expanded[\"start\"] = df_expanded[\"start\"].dt.round(\"min\")\n",
    "        if \"end\" in df_expanded.columns:\n",
    "            df_expanded[\"end\"] = pd.to_datetime(df_expanded[\"end\"], format=\"ISO8601\", errors=\"coerce\")\n",
    "            df_expanded[\"end\"] = df_expanded[\"end\"].dt.round(\"min\")\n",
    "\n",
    "    return df_expanded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_speed_data(df, metric, data_column=\"data\"):\n",
    "    new_rows = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            # Convert string JSON to dictionary safely\n",
    "            speed_data = ast.literal_eval(row[data_column].replace(\"'\", \"\\\"\")) if isinstance(row[data_column], str) else row[data_column]\n",
    "            \n",
    "            total_speed = 0\n",
    "            num_samples = 0\n",
    "\n",
    "            if isinstance(speed_data, dict) and \"samples\" in speed_data:\n",
    "                for sample in speed_data[\"samples\"]:\n",
    "                    if \"speed\" in sample and \"inKilometersPerHour\" in sample[\"speed\"]:\n",
    "                        total_speed += sample[\"speed\"][\"inKilometersPerHour\"]\n",
    "                        num_samples += 1\n",
    "            \n",
    "            # Compute average speed (avoid division by zero)\n",
    "            avg_speed = (total_speed / num_samples) if num_samples > 0 else None\n",
    "\n",
    "            # Compute total time spent using start and end timestamps\n",
    "            total_time_spent = None\n",
    "            if \"start\" in row and \"end\" in row:\n",
    "                try:\n",
    "                    start_time = datetime.fromisoformat(row[\"start\"].replace(\"Z\", \"\"))\n",
    "                    end_time = datetime.fromisoformat(row[\"end\"].replace(\"Z\", \"\"))\n",
    "                    total_time_spent = (end_time - start_time).total_seconds() / 60  # Convert to minutes\n",
    "                except Exception:\n",
    "                    total_time_spent = None  # Handle incorrect formats\n",
    "\n",
    "            # Append calculated values\n",
    "            row_data = row.to_dict()\n",
    "            row_data[\"total_time_spent\"] = total_time_spent\n",
    "            row_data[\"average_speed_kmh\"] = avg_speed\n",
    "\n",
    "            new_rows.append(row_data)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing row: {row[data_column]} - {e}\")\n",
    "\n",
    "\n",
    "        df_expanded = pd.DataFrame(new_rows)\n",
    "        \n",
    "        if \"start\" in df_expanded.columns:\n",
    "            df_expanded[\"start\"] = pd.to_datetime(df_expanded[\"start\"], format=\"ISO8601\", errors=\"coerce\")\n",
    "            df_expanded[\"start\"] = df_expanded[\"start\"].dt.round(\"min\")\n",
    "        if \"end\" in df_expanded.columns:\n",
    "            df_expanded[\"end\"] = pd.to_datetime(df_expanded[\"end\"], format=\"ISO8601\", errors=\"coerce\")\n",
    "            df_expanded[\"end\"] = df_expanded[\"end\"].dt.round(\"min\")\n",
    "\n",
    "    return df_expanded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ basalMetabolicRate CSV file does not exist\n",
      "No basalMetabolicRate stats for the user: gaurav_surtani - 'NoneType' object has no attribute 'drop'\n"
     ]
    }
   ],
   "source": [
    "metric = METRICS[2] # basalMetabolicRate\n",
    "\n",
    "try:\n",
    "    df = read_csv(username, metric)\n",
    "    drop_columns(df, metric)\n",
    "    df = expand_data_column(df, metric)\n",
    "    df = df.drop(columns=[\"basalMetabolicRate_basalMetabolicRate_inWatts\"])\n",
    "    df = df.rename(columns={\"basalMetabolicRate_basalMetabolicRate_inKilocaloriesPerDay\": \"basalMetabolicRate_inKilocaloriesPerDay\"})\n",
    "    os.makedirs(f\"Data/{username}/Cleaned/\", exist_ok=True) \n",
    "    file_path = os.path.join(data_dir, f\"./{username}/Cleaned/{metric}_{username}_Cleaned.csv\")\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(df.head())\n",
    "except Exception as e:\n",
    "    print(f\"No basalMetabolicRate stats for the user: {username} - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ bodyFat CSV file does not exist\n",
      "No bodyFat stats for the user: gaurav_surtani - 'NoneType' object has no attribute 'drop'\n"
     ]
    }
   ],
   "source": [
    "metric = METRICS[5] # bodyFat\n",
    "\n",
    "try: \n",
    "    df = read_csv(username, metric)\n",
    "    drop_columns(df, metric)\n",
    "    df = expand_data_column(df, metric)\n",
    "    os.makedirs(f\"Data/{username}/Cleaned/\", exist_ok=True) \n",
    "    file_path = os.path.join(data_dir, f\"./{username}/Cleaned/{metric}_{username}_Cleaned.csv\")\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(df.head())\n",
    "except Exception as e:\n",
    "    print(f\"No bodyFat stats for the user: {username} - {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               app                       end  \\\n",
      "0          com.fitbit.FitbitMobile 2025-01-21 03:01:00+00:00   \n",
      "1  com.google.android.apps.fitness 2025-01-21 03:01:00+00:00   \n",
      "2          com.fitbit.FitbitMobile 2025-01-21 03:02:00+00:00   \n",
      "3  com.google.android.apps.fitness 2025-01-21 03:02:00+00:00   \n",
      "4          com.fitbit.FitbitMobile 2025-01-21 03:13:00+00:00   \n",
      "\n",
      "                      start  distance_inKilometers  distance_inMiles  \\\n",
      "0 2025-01-21 03:00:00+00:00               0.000671          0.000417   \n",
      "1 2025-01-21 03:00:00+00:00               0.000671          0.000417   \n",
      "2 2025-01-21 03:01:00+00:00               0.002013          0.001251   \n",
      "3 2025-01-21 03:01:00+00:00               0.002013          0.001251   \n",
      "4 2025-01-21 03:12:00+00:00               0.001342          0.000834   \n",
      "\n",
      "   distance_total_time  \n",
      "0                  1.0  \n",
      "1                  1.0  \n",
      "2                  1.0  \n",
      "3                  1.0  \n",
      "4                  1.0  \n"
     ]
    }
   ],
   "source": [
    "metric = METRICS[9] # distance\n",
    "\n",
    "try: \n",
    "    df = read_csv(username, metric)\n",
    "    drop_columns(df, metric)\n",
    "    df = expand_data_column(df, metric)\n",
    "    df = df.drop(columns=[\"distance_distance_inFeet\",\"distance_distance_inInches\",\"distance_distance_inMeters\"])\n",
    "    df = df.rename(columns={\"distance_distance_inKilometers\": \"distance_inKilometers\", \"distance_distance_inMiles\": \"distance_inMiles\"})\n",
    "    os.makedirs(f\"Data/{username}/Cleaned/\", exist_ok=True) \n",
    "    file_path = os.path.join(data_dir, f\"./{username}/Cleaned/{metric}_{username}_Cleaned.csv\")\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(df.head())\n",
    "except Exception as e:\n",
    "    print(f\"No distance stats for the user: {username} - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       app                       end  \\\n",
      "0  com.fitbit.FitbitMobile 2025-02-13 09:11:00+00:00   \n",
      "1  com.fitbit.FitbitMobile 2025-02-15 05:47:00+00:00   \n",
      "2  com.fitbit.FitbitMobile 2025-02-15 13:33:00+00:00   \n",
      "3  com.fitbit.FitbitMobile 2025-02-17 07:38:00+00:00   \n",
      "4  com.fitbit.FitbitMobile 2025-02-17 09:17:00+00:00   \n",
      "\n",
      "                      start exerciseSession_endZoneOffset_id  \\\n",
      "0 2025-02-13 08:50:00+00:00                           +05:30   \n",
      "1 2025-02-15 05:23:00+00:00                           +05:30   \n",
      "2 2025-02-15 13:02:00+00:00                           +05:30   \n",
      "3 2025-02-17 07:11:00+00:00                           +05:30   \n",
      "4 2025-02-17 08:34:00+00:00                           +05:30   \n",
      "\n",
      "   exerciseSession_endZoneOffset_totalSeconds  exerciseSession_exerciseType  \\\n",
      "0                                       19800                            79   \n",
      "1                                       19800                            79   \n",
      "2                                       19800                            79   \n",
      "3                                       19800                            79   \n",
      "4                                       19800                            79   \n",
      "\n",
      "  exerciseSession_laps exerciseSession_notes exerciseSession_segments  \\\n",
      "0                   []                  None                       []   \n",
      "1                   []                  None                       []   \n",
      "2                   []                  None                       []   \n",
      "3                   []                  None                       []   \n",
      "4                   []                  None                       []   \n",
      "\n",
      "  exerciseSession_startZoneOffset_id  \\\n",
      "0                             +05:30   \n",
      "1                             +05:30   \n",
      "2                             +05:30   \n",
      "3                             +05:30   \n",
      "4                             +05:30   \n",
      "\n",
      "   exerciseSession_startZoneOffset_totalSeconds exerciseSession_title  \\\n",
      "0                                         19800                  None   \n",
      "1                                         19800                  None   \n",
      "2                                         19800                  None   \n",
      "3                                         19800                  None   \n",
      "4                                         19800                  None   \n",
      "\n",
      "   exerciseSession_total_time  \n",
      "0                        21.0  \n",
      "1                        24.0  \n",
      "2                        31.0  \n",
      "3                        27.0  \n",
      "4                        43.0  \n"
     ]
    }
   ],
   "source": [
    "metric = METRICS[10] # exerciseSession\n",
    "\n",
    "try:\n",
    "    df = read_csv(username, metric)\n",
    "    drop_columns(df, metric)\n",
    "    df = expand_data_column(df, metric)\n",
    "    os.makedirs(f\"Data/{username}/Cleaned/\", exist_ok=True) \n",
    "    file_path = os.path.join(data_dir, f\"./{username}/Cleaned/{metric}_{username}_Cleaned.csv\")\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(df.head())\n",
    "except Exception as e:\n",
    "    print(f\"No exerciseSession stats for the user: {username} - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       app                       end  \\\n",
      "0  com.fitbit.FitbitMobile 2025-01-23 05:26:00+00:00   \n",
      "1  com.fitbit.FitbitMobile 2025-01-25 10:07:00+00:00   \n",
      "2  com.fitbit.FitbitMobile 2025-01-26 15:33:00+00:00   \n",
      "3  com.fitbit.FitbitMobile 2025-01-28 10:49:00+00:00   \n",
      "4  com.fitbit.FitbitMobile 2025-01-28 15:12:00+00:00   \n",
      "\n",
      "                      start  elevationGained_elevation_inFeet  \\\n",
      "0 2025-01-23 05:25:00+00:00                                20   \n",
      "1 2025-01-25 10:06:00+00:00                                20   \n",
      "2 2025-01-26 15:32:00+00:00                                10   \n",
      "3 2025-01-28 10:48:00+00:00                                30   \n",
      "4 2025-01-28 15:11:00+00:00                                10   \n",
      "\n",
      "   elevationGained_elevation_inMeters  elevationGained_total_time  \n",
      "0                               6.096                         1.0  \n",
      "1                               6.096                         1.0  \n",
      "2                               3.048                         1.0  \n",
      "3                               9.144                         1.0  \n",
      "4                               3.048                         1.0  \n"
     ]
    }
   ],
   "source": [
    "metric = METRICS[11] # elevationGained\n",
    "\n",
    "try:\n",
    "    df = read_csv(username, metric)\n",
    "    drop_columns(df, metric)\n",
    "    df = expand_data_column(df, metric)\n",
    "    df = df.drop(columns=[\"elevationGained_elevation_inKilometers\",\"elevationGained_elevation_inInches\", \"elevationGained_elevation_inMiles\"])\n",
    "    os.makedirs(f\"Data/{username}/Cleaned/\", exist_ok=True) \n",
    "    file_path = os.path.join(data_dir, f\"./{username}/Cleaned/{metric}_{username}_Cleaned.csv\")\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(df.head())\n",
    "except Exception as e:\n",
    "    print(f\"No elevationGained stats for the user: {username} - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       app                       end  \\\n",
      "0  com.fitbit.FitbitMobile 2025-01-23 05:26:00+00:00   \n",
      "1  com.fitbit.FitbitMobile 2025-01-25 10:07:00+00:00   \n",
      "2  com.fitbit.FitbitMobile 2025-01-26 15:33:00+00:00   \n",
      "3  com.fitbit.FitbitMobile 2025-01-28 10:49:00+00:00   \n",
      "4  com.fitbit.FitbitMobile 2025-01-28 15:12:00+00:00   \n",
      "\n",
      "                      start  floorsClimbed_floors  floorsClimbed_total_time  \n",
      "0 2025-01-23 05:25:00+00:00                     2                       1.0  \n",
      "1 2025-01-25 10:06:00+00:00                     2                       1.0  \n",
      "2 2025-01-26 15:32:00+00:00                     1                       1.0  \n",
      "3 2025-01-28 10:48:00+00:00                     3                       1.0  \n",
      "4 2025-01-28 15:11:00+00:00                     1                       1.0  \n"
     ]
    }
   ],
   "source": [
    "metric = METRICS[12] # floorsClimbed\n",
    "\n",
    "try:\n",
    "    df = read_csv(username, metric)\n",
    "    drop_columns(df, metric)\n",
    "    df = expand_data_column(df, metric)\n",
    "    os.makedirs(f\"Data/{username}/Cleaned/\", exist_ok=True) \n",
    "    file_path = os.path.join(data_dir, f\"./{username}/Cleaned/{metric}_{username}_Cleaned.csv\")\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(df.head())\n",
    "except Exception as e:\n",
    "    print(f\"No floorsClimbed stats for the user: {username} - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       app                     start  beatsPerMinute\n",
      "0  com.fitbit.FitbitMobile 2025-01-21 13:17:00+00:00              94\n",
      "1  com.fitbit.FitbitMobile 2025-01-21 13:18:00+00:00              76\n",
      "2  com.fitbit.FitbitMobile 2025-01-21 13:19:00+00:00              76\n",
      "3  com.fitbit.FitbitMobile 2025-01-21 13:20:00+00:00              78\n",
      "4  com.fitbit.FitbitMobile 2025-01-21 13:21:00+00:00              76\n"
     ]
    }
   ],
   "source": [
    "metric = METRICS[13] # heartRate\n",
    "\n",
    "try:\n",
    "    df = read_csv(username, metric)\n",
    "    drop_columns(df, metric)\n",
    "    df = expand_heart_beat(df, metric)\n",
    "    df = df.rename(columns={\"time\": \"start\"})\n",
    "    os.makedirs(f\"Data/{username}/Cleaned/\", exist_ok=True) \n",
    "    file_path = os.path.join(data_dir, f\"./{username}/Cleaned/{metric}_{username}_Cleaned.csv\")\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(df.head())\n",
    "except Exception as e:\n",
    "    print(f\"No heartRate stats for the user: {username} - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ height CSV file does not exist\n",
      "No height stats for the user: gaurav_surtani - 'NoneType' object has no attribute 'drop'\n"
     ]
    }
   ],
   "source": [
    "metric = METRICS[14] # height\n",
    "\n",
    "try:\n",
    "    df = read_csv(username, metric)\n",
    "    drop_columns(df, metric)\n",
    "    df = expand_data_column(df, metric)\n",
    "    df = df.drop(columns=[\"height_height_inKilometers\",\"height_height_inMiles\"])\n",
    "    df = df.rename(columns={\"height_height_inFeet\": \"height_inFeet\", \"height_height_inInches\": \"height_inInches\", \"height_height_inMeters\": \"height_inMeters\"})\n",
    "    os.makedirs(f\"Data/{username}/Cleaned/\", exist_ok=True) \n",
    "    file_path = os.path.join(data_dir, f\"./{username}/Cleaned/{metric}_{username}_Cleaned.csv\")\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(df.head())\n",
    "except Exception as e:\n",
    "    print(f\"No height stats for the user: {username} - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ nutrition CSV file does not exist\n",
      "No nutrition stats for the user: gaurav_surtani - 'NoneType' object has no attribute 'drop'\n"
     ]
    }
   ],
   "source": [
    "metric = METRICS[19] # nutrition\n",
    "\n",
    "try:\n",
    "    df = read_csv(username, metric)\n",
    "    drop_columns(df, metric)\n",
    "    df = extract_vitamin_grams(df, metric)\n",
    "    os.makedirs(f\"Data/{username}/Cleaned/\", exist_ok=True) \n",
    "    file_path = os.path.join(data_dir, f\"./{username}/Cleaned/{metric}_{username}_Cleaned.csv\")\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(df.head())\n",
    "except Exception as e:\n",
    "    print(f\"No nutrition stats for the user: {username} - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ oxygenSaturation CSV file does not exist\n",
      "No oxygenSaturation stats for the user: gaurav_surtani - 'NoneType' object has no attribute 'drop'\n"
     ]
    }
   ],
   "source": [
    "metric = METRICS[21]  # oxygenSaturation\n",
    "\n",
    "try:\n",
    "    df = read_csv(username, metric)\n",
    "    drop_columns(df, metric)\n",
    "    df = expand_data_column(df, metric)\n",
    "    os.makedirs(f\"Data/{username}/Cleaned/\", exist_ok=True) \n",
    "    file_path = os.path.join(data_dir, f\"./{username}/Cleaned/{metric}_{username}_Cleaned.csv\")\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(df.head())\n",
    "except Exception as e:\n",
    "    print(f\"No oxygenSaturation stats for the user: {username} - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       app                       end  \\\n",
      "0  com.fitbit.FitbitMobile 2025-02-08 20:18:00+00:00   \n",
      "1  com.fitbit.FitbitMobile 2025-02-19 06:40:00+00:00   \n",
      "2  com.fitbit.FitbitMobile 2025-02-19 14:00:00+00:00   \n",
      "3  com.fitbit.FitbitMobile 2025-02-20 02:24:00+00:00   \n",
      "4  com.fitbit.FitbitMobile 2025-02-21 14:51:00+00:00   \n",
      "\n",
      "                      start  sleep_stage_1  sleep_stage_2  sleep_stage_3  \\\n",
      "0 2025-02-08 14:50:00+00:00           35.5            0.0            0.0   \n",
      "1 2025-02-19 05:02:00+00:00            0.0           98.0            0.0   \n",
      "2 2025-02-19 11:21:00+00:00           76.0           83.0            0.0   \n",
      "3 2025-02-19 20:37:00+00:00           49.5            0.0            0.0   \n",
      "4 2025-02-21 08:58:00+00:00           46.0            0.0            0.0   \n",
      "\n",
      "   sleep_stage_4  sleep_stage_5  sleep_stage_6  sleep_stage_7  sleep_stage_8  \\\n",
      "0          182.0           59.5           51.0            0.0            0.0   \n",
      "1            0.0            0.0            0.0            0.0            0.0   \n",
      "2            0.0            0.0            0.0            0.0            0.0   \n",
      "3          205.5           69.5           22.5            0.0            0.0   \n",
      "4          185.5           47.0           74.5            0.0            0.0   \n",
      "\n",
      "   total_sleep_time  \n",
      "0             328.0  \n",
      "1              98.0  \n",
      "2             159.0  \n",
      "3             347.0  \n",
      "4             353.0  \n"
     ]
    }
   ],
   "source": [
    "metric = METRICS[25] # sleepSession\n",
    "\n",
    "try:\n",
    "    df = read_csv(username, metric)\n",
    "    drop_columns(df, metric)\n",
    "    df = process_sleep_data(df, metric)\n",
    "    df = df.drop(columns=[\"data\"])\n",
    "    # df = df.rename(columns={\"data\": \"sleep_data\"})\n",
    "    os.makedirs(f\"Data/{username}/Cleaned/\", exist_ok=True) \n",
    "    file_path = os.path.join(data_dir, f\"./{username}/Cleaned/{metric}_{username}_Cleaned.csv\")\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(df.head())\n",
    "except Exception as e:\n",
    "    print(f\"No sleepSession stats for the user: {username} - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               app                       end  \\\n",
      "0  com.google.android.apps.fitness 2025-01-21 03:21:00+00:00   \n",
      "1  com.google.android.apps.fitness 2025-01-21 03:55:00+00:00   \n",
      "2  com.google.android.apps.fitness 2025-01-21 03:56:00+00:00   \n",
      "3  com.google.android.apps.fitness 2025-01-21 04:48:00+00:00   \n",
      "4  com.google.android.apps.fitness 2025-01-21 04:49:00+00:00   \n",
      "\n",
      "                      start  speed_total_time_spent  average_speed_kmh  \n",
      "0 2025-01-21 03:21:00+00:00                0.000017           2.619040  \n",
      "1 2025-01-21 03:55:00+00:00                0.000017           3.347350  \n",
      "2 2025-01-21 03:56:00+00:00                0.000017           2.762229  \n",
      "3 2025-01-21 04:48:00+00:00                0.000017           3.505364  \n",
      "4 2025-01-21 04:49:00+00:00                0.000017           2.532118  \n"
     ]
    }
   ],
   "source": [
    "metric = METRICS[26] # speed\n",
    "\n",
    "try:\n",
    "    df = read_csv(username, metric)\n",
    "    drop_columns(df, metric)\n",
    "    df = process_speed_data(df, metric)\n",
    "    df = df.drop(columns=[\"data\"])\n",
    "    df = df.rename(columns={\"total_time_spent\": \"speed_total_time_spent\"})\n",
    "    os.makedirs(f\"Data/{username}/Cleaned/\", exist_ok=True) \n",
    "    file_path = os.path.join(data_dir, f\"./{username}/Cleaned/{metric}_{username}_Cleaned.csv\")\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(df.head())\n",
    "except Exception as e:\n",
    "    print(f\"No speed stats for the user: {username} - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               app                     start  steps_count\n",
      "0          com.fitbit.FitbitMobile 2025-01-21 03:00:00+00:00            1\n",
      "1  com.google.android.apps.fitness 2025-01-21 03:00:00+00:00            1\n",
      "2          com.fitbit.FitbitMobile 2025-01-21 03:01:00+00:00            3\n",
      "3  com.google.android.apps.fitness 2025-01-21 03:01:00+00:00            3\n",
      "4  com.google.android.apps.fitness 2025-01-21 03:02:00+00:00            1\n"
     ]
    }
   ],
   "source": [
    "metric = METRICS[27] # steps\n",
    "\n",
    "try:\n",
    "    df = read_csv(username, metric)\n",
    "    drop_columns(df, metric)\n",
    "    df = expand_data_column(df, metric)\n",
    "    os.makedirs(f\"Data/{username}/Cleaned/\", exist_ok=True) \n",
    "    file_path = os.path.join(data_dir, f\"./{username}/Cleaned/{metric}_{username}_Cleaned.csv\")\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(df.head())\n",
    "except Exception as e:\n",
    "    print(f\"No steps stats for the user: {username} - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               app                       end  \\\n",
      "0  com.google.android.apps.fitness 2025-01-21 01:30:00+00:00   \n",
      "1          com.fitbit.FitbitMobile 2025-01-21 01:45:00+00:00   \n",
      "2  com.google.android.apps.fitness 2025-01-21 01:45:00+00:00   \n",
      "3  com.google.android.apps.fitness 2025-01-21 01:45:00+00:00   \n",
      "4          com.fitbit.FitbitMobile 2025-01-21 02:00:00+00:00   \n",
      "\n",
      "                      start  totalCaloriesBurned_energy_inKilocalories  \\\n",
      "0 2025-01-21 01:30:00+00:00                                   0.000019   \n",
      "1 2025-01-21 01:30:00+00:00                                  18.205650   \n",
      "2 2025-01-21 01:30:00+00:00                                  18.205650   \n",
      "3 2025-01-21 01:45:00+00:00                                   0.000019   \n",
      "4 2025-01-21 01:45:00+00:00                                  18.205650   \n",
      "\n",
      "   totalCaloriesBurned_total_time  \n",
      "0                             0.0  \n",
      "1                            15.0  \n",
      "2                            15.0  \n",
      "3                             0.0  \n",
      "4                            15.0  \n"
     ]
    }
   ],
   "source": [
    "metric = METRICS[29]  # totalCaloriesBurned\n",
    "\n",
    "try:\n",
    "    df = read_csv(username, metric)\n",
    "    drop_columns(df, metric)\n",
    "    df = expand_data_column(df, metric)\n",
    "    df = df.drop(columns=[\"totalCaloriesBurned_energy_inJoules\", \"totalCaloriesBurned_energy_inCalories\", \"totalCaloriesBurned_energy_inKilojoules\"])\n",
    "    os.makedirs(f\"Data/{username}/Cleaned/\", exist_ok=True) \n",
    "    file_path = os.path.join(data_dir, f\"./{username}/Cleaned/{metric}_{username}_Cleaned.csv\")\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(df.head())\n",
    "except Exception as e:\n",
    "    print(f\"No totalCaloriesBurned stats for the user: {username} - {e}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ weight CSV file does not exist\n",
      "No weight stats for the user: gaurav_surtani - 'NoneType' object has no attribute 'drop'\n"
     ]
    }
   ],
   "source": [
    "metric = METRICS[31] # weight\n",
    "\n",
    "try:\n",
    "    df = read_csv(username, metric)\n",
    "    drop_columns(df, metric)\n",
    "    df = expand_data_column(df, metric)\n",
    "    df = df.drop(columns=[\"weight_weight_inGrams\", \"weight_weight_inMicrograms\", \"weight_weight_inMilligrams\", \"weight_weight_inOunces\"])\n",
    "    df = df.rename(columns={\"weight_weight_inKilograms\": \"weight_inKilograms\", \"weight_weight_inPounds\": \"weight_inPounds\"})\n",
    "    os.makedirs(f\"Data/{username}/Cleaned/\", exist_ok=True) \n",
    "    file_path = os.path.join(data_dir, f\"./{username}/Cleaned/{metric}_{username}_Cleaned.csv\")\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(df.head())\n",
    "except Exception as e:\n",
    "    print(f\"No weight stats for the user: {username} - {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "introspectai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
