# -*- coding: utf-8 -*-
"""2_joinDS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fIHvWymXBZjGZv1Hhx0lbUjF4f79kSfl
"""

import pandas as pd
import matplotlib.pyplot as plt

# Load the existing processed data
def load_and_analyze_core_metrics(file_path='health_data_10min_intervals.csv'):
    """
    Load and analyze core metrics from the 10-minute interval data
    """
    # Read the CSV file
    df = pd.read_csv(file_path)

    # Convert timestamp to datetime
    df['timestamp'] = pd.to_datetime(df['timestamp'])
    df.set_index('timestamp', inplace=True)

    # Select core metrics
    core_metrics = ['steps_10min', 'bpm', 'spo2_spo2']
    core_df = df[core_metrics].copy()

    # Rename columns for clarity
    core_df.columns = ['Steps', 'Heart Rate', 'SpO2']

    # Display basic information
    print("Data Summary:")
    print("-" * 50)
    print(f"Time range: {core_df.index.min()} to {core_df.index.max()}")
    print(f"Total intervals: {len(core_df)}")

    # Calculate completeness
    completeness = (core_df.count() / len(core_df) * 100).sort_values(ascending=False)
    print("\nData Completeness (%):")
    print("-" * 50)
    for metric, percentage in completeness.items():
        print(f"{metric:<20} {percentage:>6.2f}%")

    # Display basic statistics
    print("\nBasic Statistics:")
    print("-" * 50)
    print(core_df.describe())

    return core_df

# Load and analyze the data
core_metrics_df = load_and_analyze_core_metrics()

# Display first few rows
print("\nFirst few rows of data:")
print("-" * 50)
print(core_metrics_df.head())

core_metrics_df

def analyze_missing_values(df):
    """
    Analyze missing values in the dataset
    """
    # Count total NATs
    total_nats = df.isna().sum()

    # Calculate percentage of NATs
    percent_nats = (df.isna().sum() / len(df)) * 100

    # Combine counts and percentages
    missing_info = pd.DataFrame({
        'Missing Values': total_nats,
        'Percentage Missing': percent_nats
    }).sort_values('Missing Values', ascending=False)

    print("\nMissing Values Analysis:")
    print("-" * 50)
    for column, row in missing_info.iterrows():
        print(f"{column:<20}: {int(row['Missing Values']):>10,} NATs ({row['Percentage Missing']:>6.2f}%)")

    print(f"\nTotal rows in dataset: {len(df):,}")
    print(f"Rows with any missing value: {df.isna().any(axis=1).sum():,}")
    print(f"Completely empty rows: {df.isna().all(axis=1).sum():,}")

# Load and analyze the data
df = pd.read_csv('health_data_10min_intervals.csv')
df['timestamp'] = pd.to_datetime(df['timestamp'])
df.set_index('timestamp', inplace=True)

# Focus on core metrics
core_metrics = ['steps_10min', 'bpm', 'spo2_spo2']
core_df = df[core_metrics].copy()
core_df.columns = ['Steps', 'Heart Rate', 'SpO2']

# Analyze missing values
analyze_missing_values(core_df)

import pandas as pd
import numpy as np

def analyze_value_presence(df):
    """
    Analyze combinations of present values in the dataset
    """
    # Create boolean masks for non-missing values
    steps_present = ~df['Steps'].isna()
    hr_present = ~df['Heart Rate'].isna()
    spo2_present = ~df['SpO2'].isna()

    # Count different combinations
    total_rows = len(df)

    print("\nValue Presence Analysis:")
    print("-" * 50)
    print(f"Total rows: {total_rows:,}")

    print("\nSingle Metric Present:")
    print(f"Only Steps: {(steps_present & ~hr_present & ~spo2_present).sum():,} rows ({(steps_present & ~hr_present & ~spo2_present).sum()/total_rows*100:.2f}%)")
    print(f"Only Heart Rate: {(~steps_present & hr_present & ~spo2_present).sum():,} rows ({(~steps_present & hr_present & ~spo2_present).sum()/total_rows*100:.2f}%)")
    print(f"Only SpO2: {(~steps_present & ~hr_present & spo2_present).sum():,} rows ({(~steps_present & ~hr_present & spo2_present).sum()/total_rows*100:.2f}%)")

    print("\nTwo Metrics Present:")
    print(f"Steps + Heart Rate: {(steps_present & hr_present & ~spo2_present).sum():,} rows ({(steps_present & hr_present & ~spo2_present).sum()/total_rows*100:.2f}%)")
    print(f"Steps + SpO2: {(steps_present & ~hr_present & spo2_present).sum():,} rows ({(steps_present & ~hr_present & spo2_present).sum()/total_rows*100:.2f}%)")
    print(f"Heart Rate + SpO2: {(~steps_present & hr_present & spo2_present).sum():,} rows ({(~steps_present & hr_present & spo2_present).sum()/total_rows*100:.2f}%)")

    print("\nAll Metrics Present:")
    print(f"Steps + Heart Rate + SpO2: {(steps_present & hr_present & spo2_present).sum():,} rows ({(steps_present & hr_present & spo2_present).sum()/total_rows*100:.2f}%)")

    print("\nNo Metrics Present:")
    print(f"Completely empty rows: {(~steps_present & ~hr_present & ~spo2_present).sum():,} rows ({(~steps_present & ~hr_present & ~spo2_present).sum()/total_rows*100:.2f}%)")

# Load the datasets
df = pd.read_csv('health_data_10min_intervals.csv')
df['timestamp'] = pd.to_datetime(df['timestamp'])
df.set_index('timestamp', inplace=True)

# Focus on core metrics
core_metrics = ['steps_10min', 'bpm', 'spo2_spo2']  # Using spo2_spo2 from merged data
core_df = df[core_metrics].copy()
core_df.columns = ['Steps', 'Heart Rate', 'SpO2']

# Analyze value presence
analyze_value_presence(core_df)

def analyze_time_patterns(df):
    """
    Analyze when data is present/missing for each metric
    """
    # Add time-based columns
    df['hour'] = df.index.hour
    df['day_of_week'] = df.index.dayofweek
    df['month'] = df.index.month
    df['year'] = df.index.year

    print("Data Coverage by Time Period:")
    print("-" * 50)

    # Analyze by year
    print("\nYearly Coverage:")
    yearly = df.groupby('year').apply(lambda x: pd.Series({
        'Steps Present (%)': (~x['Steps'].isna()).mean() * 100,
        'Heart Rate Present (%)': (~x['Heart Rate'].isna()).mean() * 100,
        'SpO2 Present (%)': (~x['SpO2'].isna()).mean() * 100,
        'Total Records': len(x)
    }))
    print(yearly.round(2))

    # Analyze by hour
    print("\nHourly Coverage:")
    hourly = df.groupby('hour').apply(lambda x: pd.Series({
        'Steps Present (%)': (~x['Steps'].isna()).mean() * 100,
        'Heart Rate Present (%)': (~x['Heart Rate'].isna()).mean() * 100,
        'SpO2 Present (%)': (~x['SpO2'].isna()).mean() * 100,
        'Total Records': len(x)
    }))
    print(hourly.round(2))

    # Analyze by day of week
    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
    print("\nDaily Coverage:")
    daily = df.groupby('day_of_week').apply(lambda x: pd.Series({
        'Steps Present (%)': (~x['Steps'].isna()).mean() * 100,
        'Heart Rate Present (%)': (~x['Heart Rate'].isna()).mean() * 100,
        'SpO2 Present (%)': (~x['SpO2'].isna()).mean() * 100,
        'Total Records': len(x)
    }))
    daily.index = days
    print(daily.round(2))

# Load and analyze the data
df = pd.read_csv('health_data_10min_intervals.csv')
df['timestamp'] = pd.to_datetime(df['timestamp'])
df.set_index('timestamp', inplace=True)

# Focus on core metrics
core_metrics = ['steps_10min', 'bpm', 'spo2_spo2']
core_df = df[core_metrics].copy()
core_df.columns = ['Steps', 'Heart Rate', 'SpO2']

# Analyze time patterns
analyze_time_patterns(core_df)

import pandas as pd
import numpy as np

# Load the data
df = pd.read_csv('health_data_10min_intervals.csv')
df['timestamp'] = pd.to_datetime(df['timestamp'])
df.set_index('timestamp', inplace=True)

# Focus on core metrics
core_metrics = ['steps_10min', 'bpm', 'spo2_spo2']
core_df = df[core_metrics].copy()
core_df.columns = ['Steps', 'Heart Rate', 'SpO2']

# Create boolean masks for non-missing values
steps_present = ~core_df['Steps'].isna()
hr_present = ~core_df['Heart Rate'].isna()
spo2_present = ~core_df['SpO2'].isna()

# Create mask for rows with at least 2 metrics present
two_or_more_metrics = (
    (steps_present & hr_present) |  # Steps + HR
    (steps_present & spo2_present) |  # Steps + SpO2
    (hr_present & spo2_present)  # HR + SpO2
)

# Create new DataFrame with rows having 2+ metrics
df_two_metrics = core_df[two_or_more_metrics].copy()

# Display information about the new DataFrame
print("DataFrame with 2+ metrics present:")
print("-" * 50)
print(f"Total rows: {len(df_two_metrics):,}")
print(f"\nDate range: {df_two_metrics.index.min()} to {df_two_metrics.index.max()}")
print("\nSample of data (first 10 rows):")
print(df_two_metrics.head(10))

# Save this DataFrame
df_two_metrics.to_csv('health_data_2plus_metrics.csv')
print("\nSaved to: health_data_2plus_metrics.csv")

# Show value counts of which combinations are present
combinations = pd.DataFrame({
    'Steps + HR': (steps_present & hr_present & ~spo2_present)[two_or_more_metrics],
    'Steps + SpO2': (steps_present & ~hr_present & spo2_present)[two_or_more_metrics],
    'HR + SpO2': (~steps_present & hr_present & spo2_present)[two_or_more_metrics],
    'All Three': (steps_present & hr_present & spo2_present)[two_or_more_metrics]
})

print("\nCombination counts:")
print("-" * 50)
for column in combinations.columns:
    count = combinations[column].sum()
    percentage = (count / len(df_two_metrics)) * 100
    print(f"{column}: {count:,} rows ({percentage:.2f}%)")

import pandas as pd

# Load the data
df = pd.read_csv('health_data_10min_intervals.csv')
df['timestamp'] = pd.to_datetime(df['timestamp'])
df.set_index('timestamp', inplace=True)

# Focus on core metrics
core_metrics = ['steps_10min', 'bpm', 'spo2_spo2']
core_df = df[core_metrics].copy()
core_df.columns = ['Steps', 'Heart Rate', 'SpO2']

# Check completely empty rows
empty_rows = core_df[core_df.isna().all(axis=1)]
non_empty_rows = core_df.dropna(how='all')

print("Empty Rows Analysis:")
print("-" * 50)
print(f"Total rows: {len(core_df):,}")
print(f"Completely empty rows: {len(empty_rows):,} ({len(empty_rows)/len(core_df)*100:.2f}%)")
print(f"Rows with at least one value: {len(non_empty_rows):,} ({len(non_empty_rows)/len(core_df)*100:.2f}%)")

# Show sample of empty rows with their timestamps
print("\nSample of empty rows:")
print("-" * 50)
print(empty_rows.head())

# Show distribution of empty rows by year
yearly_empty = empty_rows.groupby(empty_rows.index.year).size()
print("\nEmpty rows by year:")
print("-" * 50)
for year, count in yearly_empty.items():
    print(f"{year}: {count:,} rows")

# Create a cleaned dataset without empty rows
cleaned_df = core_df.dropna(how='all')
cleaned_df.to_csv('health_data_no_empty_rows.csv')
print("\nCleaned dataset saved to: health_data_no_empty_rows.csv")
print(f"Rows in cleaned dataset: {len(cleaned_df):,}")

import pandas as pd
import numpy as np

def analyze_two_metric_combinations():
    """
    Load and analyze data where at least two metrics are present
    """
    # Load the data without empty rows
    df = pd.read_csv('health_data_no_empty_rows.csv')
    df['timestamp'] = pd.to_datetime(df['timestamp'])
    df.set_index('timestamp', inplace=True)

    # Focus on core metrics
    core_metrics = ['Steps', 'Heart Rate', 'SpO2']  # Already renamed in no_empty_rows file
    core_df = df[core_metrics].copy()

    # Create boolean masks for non-missing values
    steps_present = ~core_df['Steps'].isna()
    hr_present = ~core_df['Heart Rate'].isna()
    spo2_present = ~core_df['SpO2'].isna()

    # Create mask for rows with at least 2 metrics present
    two_or_more_metrics = (
        (steps_present & hr_present) |  # Steps + HR
        (steps_present & spo2_present) |  # Steps + SpO2
        (hr_present & spo2_present)  # HR + SpO2
    )

    # Create new DataFrame with rows having 2+ metrics
    df_two_metrics = core_df[two_or_more_metrics].copy()

    # Display information about the new DataFrame
    print("DataFrame with 2+ metrics present:")
    print("-" * 50)
    print(f"Total rows in original: {len(core_df):,}")
    print(f"Rows with 2+ metrics: {len(df_two_metrics):,}")
    print(f"\nDate range: {df_two_metrics.index.min()} to {df_two_metrics.index.max()}")

    print("\nSample of data (first 5 rows):")
    print(df_two_metrics.head())

    # Save this DataFrame
    output_file = 'health_data_no_empty_rows_2plus_metrics.csv'
    df_two_metrics.to_csv(output_file)
    print(f"\nSaved to: {output_file}")

    # Show value counts of which combinations are present
    combinations = pd.DataFrame({
        'Steps + HR': (steps_present & hr_present & ~spo2_present)[two_or_more_metrics],
        'Steps + SpO2': (steps_present & ~hr_present & spo2_present)[two_or_more_metrics],
        'HR + SpO2': (~steps_present & hr_present & spo2_present)[two_or_more_metrics],
        'All Three': (steps_present & hr_present & spo2_present)[two_or_more_metrics]
    })

    print("\nCombination counts:")
    print("-" * 50)
    for column in combinations.columns:
        count = combinations[column].sum()
        percentage = (count / len(df_two_metrics)) * 100
        print(f"{column}: {count:,} rows ({percentage:.2f}%)")

    return df_two_metrics

# Run the analysis
df_two_metrics = analyze_two_metric_combinations()

